{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # VA Data tools\n",
    "  ## Tools for navigating VA Datasets\n",
    "  \n",
    "  ## History\n",
    "The VA open data portal (https://www.data.va.gov/) contains several thousand data files in Excel, CSV, and PDF formats.  Brent Brewington, using R, flattened out the dataset inventory from JSON to a CSV file.  Both the CSV file and the R code used to do this can be found at his repository:\n",
    "https://github.com/bbrewington/VA-open-data-mysandbox\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, re, requests, io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download the latest version of Brent's CSV file and save it 'locally.' I only need to do this if something changes, really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VADataInventory = requests.get('https://raw.githubusercontent.com/bbrewington/VA-open-data-mysandbox/master/va_data_inventory_links_checked_20171202.csv')\n",
    "VADataInventory.raise_for_status()\n",
    "\n",
    "megadata = open('va_data_inventory.csv', 'wb')\n",
    "for chunk in VADataInventory.iter_content(100000):\n",
    "    megadata.write(chunk)\n",
    "    \n",
    "megadata.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool!  When the file is downloaded, I'll just run from the following lines.  The use for these will become more clear as we dig through the various functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MegaData= open('va_data_inventory.csv', encoding = \"utf8\")\n",
    "megasheet = csv.reader(MegaData) # read this using the CSV module\n",
    "alldata = list(megasheet) # which is easier to work with in a list format\n",
    "headers = alldata[0]      # easily grab the headers this way\n",
    "file_extension_regex = re.compile(r'\\.((pdf|csv|xlsx?|zip|asp))', re.IGNORECASE) \n",
    "states = ['Alabama' ,'Alaska' ,'Arizona' ,'Arkansas' ,'California' ,'Colorado' ,'Connecticut' ,'Delaware' ,'Florida' ,'Georgia' ,'Hawaii' ,'Idaho' ,'Illinois' ,'Indiana' ,'Iowa' ,'Kansas' ,'Kentucky' ,'Louisiana' ,'Maine' ,'Maryland' ,'Massachusetts' ,'Michigan' ,'Minnesota' ,'Mississippi' ,'Missouri' ,'Montana' ,'Nebraska' ,'Nevada' ,'New Hampshire' ,'New Jersey' ,'New Mexico' ,'New York' ,'North Carolina' ,'North Dakota' ,'Ohio' ,'Oklahoma' ,'Oregon' ,'Pennsylvania' ,'Rhode' 'Island' ,'South Carolina' ,'South Dakota' ,'Tennessee' ,'Texas' ,'Utah' ,'Vermont' ,'Virginia' ,'Washington' ,'West' 'Virginia' ,'Wisconsin' ,'Wyoming']\n",
    "territories = ['American Samoa', 'Guam', 'Northern Mariana Islands', 'Puerto Rico']\n",
    "states_territories = states + territories\n",
    "StateDict= {\"AL\":\"Alabama\", \"AS\" : \"American Samoa\", \"AK\":\"Alaska\",\"AZ\":\"Arizona\",\"AR\":\"Arkansas\",\"CA\":\"California\",\"CO\":\"Colorado\",\"CT\":\"Connecticut\", \"DC\": \"District of Columbia\", \"DE\":\"Delaware\",\"FL\":\"Florida\",\"FM\": \"Federated States of Micronesia\", \"GA\":\"Georgia\",\"HI\":\"Hawaii\",\"GU\": \"Guam\", \"ID\":\"Idaho\",\"IL\":\"Illinois\",\"IN\":\"Indiana\",\"IA\":\"Iowa\",\"KS\":\"Kansas\",\"KY\":\"Kentucky\",\"LA\":\"Louisiana\",\"ME\":\"Maine\",\"MD\":\"Maryland\",\"MA\":\"Massachusetts\",\"MH\": \"Marshall Islands\", \"MI\":\"Michigan\",\"MN\":\"Minnesota\",\"MP\" : \"Northern Mariana Islands\", \"MS\":\"Mississippi\",\"MO\":\"Missouri\",\"MT\":\"Montana\",\"NE\":\"Nebraska\",\"NV\":\"Nevada\",\"NH\":\"New Hampshire\",\"NJ\":\"New Jersey\",\"NM\":\"New Mexico\",\"NY\":\"New York\",\"NC\":\"North Carolina\",\"ND\":\"North Dakota\",\"OH\":\"Ohio\",\"OK\":\"Oklahoma\",\"OR\":\"Oregon\",\"PA\":\"Pennsylvania\",\"PR\" : \"Puerto Rico\", \"RI\":\"Rhode Island\",\"SC\":\"South Carolina\",\"SD\":\"South Dakota\",\"TN\":\"Tennessee\",\"TX\":\"Texas\",\"UT\":\"Utah\",\"VT\":\"Vermont\",\"VA\":\"Virginia\",\"VI\": \"Version Islands\", \"WA\":\"Washington\",\"WV\":\"West Virginia\",\"WI\":\"Wisconsin\",\"WY\":\"Wyoming\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! First, note that Brent's CSV file contains the following headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without losing too much by 'overcleaning' the CSV file, these tools will help us browse through it. Remember that we are now treating this CSV file in list format. So each row is a list, and each data element is an element in the list matching the headers.  i.e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tools will help us sort through all this without 'overcleaning' this datafile. The first two are just a basic search.\n",
    "You can search a line or the entire file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vsearch(line, term): # search for any term in a line/dataset\n",
    "    search_term = re.compile(r'.*(%s).*' % (term), re.IGNORECASE )\n",
    "    fields = filter(search_term.match, alldata[line])\n",
    "    return(list(fields))\n",
    "\n",
    "def searchall(term): # search entire CSV file. The output will tell you what line it's on.\n",
    "    searchresults = []  \n",
    "    for line in range(0,len(alldata)):\n",
    "        if not vsearch(line, term) == []:\n",
    "            searchresults = searchresults + [vsearch(line, term), 'line:' + str(line -1)]\n",
    "    return(searchresults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsearch(1, 'state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted all the 'by state' datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchall('by state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the line is given, so I can pull up that dataset.  468 looks interesting.  This is a little hard to look at though.  A few more tools..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords(line): # What keywords descibe this file?\n",
    "    return(alldata[line][7])\n",
    "\n",
    "def whatformat(line):# This will tell you what format a datafile is in\n",
    "    return(alldata[line][31])\n",
    "\n",
    "\n",
    "def getheaders(line): # get headers of csv or excel file\n",
    "    earl = whaturl(line) # assuming the headers are on the first line\n",
    "    print('Getting file...') \n",
    "    # for excel files\n",
    "    if whatformat(line) in ('xlsx', 'xls'): \n",
    "        print('Excel file. Getting headers...')\n",
    "        try:\n",
    "            df = pd.read_excel(earl)\n",
    "            return(df.columns.tolist())\n",
    "        except:\n",
    "            print('There was some problem reading this file.')\n",
    "            print('Try accessing ' + earl + ' directly from your browser.')\n",
    "    # for CSV files\n",
    "    elif whatformat(line) == 'csv':\n",
    "        print('CSV file. Getting headers...')\n",
    "        try:\n",
    "            res = requests.get(whaturl(line))\n",
    "            df = pd.read_csv(io.StringIO(res.text))\n",
    "            return(df.columns.tolist())\n",
    "        except:\n",
    "            print('There was some problem reading this file.')\n",
    "            print('Try accessing ' + earl + ' directly from your browser.')\n",
    "    else:\n",
    "        print('Oh dear! This does not appear to be an excel or CSV file.')\n",
    "        \n",
    "def whaturl(line): # Where can I find the file for download\n",
    "    return(alldata[line][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords(468)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatformat(468)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whaturl(468)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will pull the headers down into a pandas dataframe.  This one could use some help. It pulls  down the entire file first to give you the headers.  There are a number of reasons why this might not always work, including the assumption that the headers are always on the first row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getheaders(468)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, like that.  How about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getheaders(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better.  Want to pull the entire dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAPandas(line): # Pull down CSV or Excel files into Pandas Dataframe\n",
    "    earl = whaturl(line) # assuming the headers are on the first line\n",
    "    print('Getting file...') \n",
    "    # for excel files\n",
    "    if whatformat(line) in ('xlsx', 'xls'): \n",
    "        print('Excel file. Retrieving into Pandas Dataframe...')\n",
    "        try:\n",
    "            df = pd.read_excel(earl)\n",
    "            return(df)\n",
    "        except:\n",
    "            print('There was some problem reading this file.')\n",
    "            print('Try accessing ' + earl + ' directly from your browser.')\n",
    "    # for CSV files\n",
    "    elif whatformat(line) == 'csv':\n",
    "        print('CSV file. Retrieving into Pandas Dataframe...')\n",
    "        try:\n",
    "            res = requests.get(whaturl(line))\n",
    "            df = pd.read_csv(io.StringIO(res.text))\n",
    "            return(df)\n",
    "        except:\n",
    "            print('There was some problem reading this file.')\n",
    "            print('Try accessing ' + earl + ' directly from your browser.')\n",
    "    else:\n",
    "        print('Oh dear! This does not appear to be an excel or CSV file.')\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAPandas(6), type(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also to be improved is the following function, which is supposed to tell you what, if any state or territory data is included in a particular header.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whatstate(line):\n",
    "    which_states = []\n",
    "    for x in alldata[line]:\n",
    "        for state in states_territories:\n",
    "            if state.lower() in x.lower():\n",
    "                which_states = which_states + [state]\n",
    "    if len(which_states) == 0:\n",
    "        return(\"No state names found\")\n",
    "    else:\n",
    "        return(list(set(which_states))) #turned into a set to remove dups, then back into list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for example. What states is covered in the first, third and seventh dataset? Note that we do include terrotories, and will have ways for sorting out territories and states. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatstate(564), whatstate(565), whatstate(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what files have state data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statedata = [] \n",
    "for i in range(0,len(alldata)):\n",
    "    if not whatstate(i) == 'No state names found':\n",
    "        statedata = statedata + [[whatstate(i)[0], i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(statedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make searching for State datasets  easier, I've used a dictionary of state and territory abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StateSearch(StateAbbreviation):\n",
    "    searchresults = []\n",
    "    term = StateDict[StateAbbreviation]\n",
    "    for line in range(0,len(alldata)):\n",
    "        if not vsearch(line, term) == []:\n",
    "            searchresults = searchresults + [vsearch(line, term), 'line:' + str(line -1)]\n",
    "    return(searchresults)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StateSearch(\"MA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other projects and future uses:\n",
    "* Find all files with the same or similar headers\n",
    "* Find data per county?\n",
    "* Make the states/territories dataset into a dictionary format using state abbreviations\n",
    "* Brent's CSV file is great, but maybe we could pull from the JSON directly?\n",
    "* Fix whatever newbie coding mistakes I have made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
